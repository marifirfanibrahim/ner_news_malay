{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f8edd7",
   "metadata": {},
   "source": [
    "# Fine-Tuning Preparation\n",
    "Based on the analysis, the confidence score is correlated with the number of labels predicted. This means that by increasing the number of predicted labels, the confidence score will increase as wel. However, this would only appply after the prediction.\n",
    "The good news is that from the analysis, there are a few label types that have shown to have poor high confidence score ratio against low confidence score. This is while some low frequency labels have good ratio. So, to increase the confidence score with less label frequency. The training data needs to be augmented. Here, there are two things that can be done for this augmentation. These are:\n",
    "- get contextual texts that corresponds to poor ratio labels.\n",
    "- synthesize training data for rare texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e800ff",
   "metadata": {},
   "source": [
    "------------\n",
    "-----------\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879704cf",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15694c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gliner import GLiNER\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7925697",
   "metadata": {},
   "source": [
    "### Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ce69f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 69905.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GLiNER(\n",
       "  (model): SpanModel(\n",
       "    (token_rep_layer): Encoder(\n",
       "      (bert_layer): Transformer(\n",
       "        (model): DebertaV2Model(\n",
       "          (embeddings): DebertaV2Embeddings(\n",
       "            (word_embeddings): Embedding(250105, 768, padding_idx=0)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (encoder): DebertaV2Encoder(\n",
       "            (layer): ModuleList(\n",
       "              (0-11): 12 x DebertaV2Layer(\n",
       "                (attention): DebertaV2Attention(\n",
       "                  (self): DisentangledSelfAttention(\n",
       "                    (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): DebertaV2SelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): DebertaV2Intermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DebertaV2Output(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (rel_embeddings): Embedding(512, 768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rnn): LstmSeq2SeqEncoder(\n",
       "      (lstm): LSTM(768, 384, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (span_rep_layer): SpanRepLayer(\n",
       "      (span_rep_layer): SpanMarker(\n",
       "        (project_start): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.4, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        )\n",
       "        (project_end): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.4, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_project): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (prompt_rep_layer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.4, inplace=False)\n",
       "      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GLiNER.from_pretrained(\"urchade/gliner_multi\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb9179",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125ec7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aae4b77b",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5206dd80",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GLiNER' object has no attribute 'collate_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3. Create data loaders using model's built-in collate function\u001b[39;00m\n\u001b[32m      2\u001b[39m train_loader = DataLoader(\n\u001b[32m      3\u001b[39m     train_data, \n\u001b[32m      4\u001b[39m     batch_size=\u001b[32m4\u001b[39m, \n\u001b[32m      5\u001b[39m     shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     collate_fn=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m val_loader = DataLoader(\n\u001b[32m     10\u001b[39m     val_data,\n\u001b[32m     11\u001b[39m     batch_size=\u001b[32m4\u001b[39m,\n\u001b[32m     12\u001b[39m     collate_fn=model.collate_fn\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1962\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1960\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1961\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1962\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1963\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1964\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'GLiNER' object has no attribute 'collate_fn'"
     ]
    }
   ],
   "source": [
    "# 3. Create data loaders using model's built-in collate function\n",
    "train_loader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=4, \n",
    "    shuffle=True,\n",
    "    collate_fn=model.collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=4,\n",
    "    collate_fn=model.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c2838",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=2e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e5653",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f936a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                 for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                     for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "    \n",
    "    # Print epoch stats\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d69506",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ac898",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"fine_tuned_gliner\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
