{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f8edd7",
   "metadata": {},
   "source": [
    "# Fine-Tuning Preparation\n",
    "Based on the analysis, the confidence score is correlated with the number of labels predicted. This means that by increasing the number of predicted labels, the confidence score will increase as wel. However, this would only appply after the prediction.\n",
    "The good news is that from the analysis, there are a few label types that have shown to have poor high confidence score ratio against low confidence score. This is while some low frequency labels have good ratio. So, to increase the confidence score with less label frequency. The training data needs to be augmented. Here, there are two things that can be done for this augmentation. These are:\n",
    "- get contextual texts that corresponds to poor ratio labels.\n",
    "- synthesize training data for rare texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e800ff",
   "metadata": {},
   "source": [
    "------------\n",
    "-----------\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879704cf",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15694c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gliner import GLiNER\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7925697",
   "metadata": {},
   "source": [
    "### Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ce69f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 62368.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GLiNER(\n",
       "  (model): SpanModel(\n",
       "    (token_rep_layer): Encoder(\n",
       "      (bert_layer): Transformer(\n",
       "        (model): DebertaV2Model(\n",
       "          (embeddings): DebertaV2Embeddings(\n",
       "            (word_embeddings): Embedding(250105, 768, padding_idx=0)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (encoder): DebertaV2Encoder(\n",
       "            (layer): ModuleList(\n",
       "              (0-11): 12 x DebertaV2Layer(\n",
       "                (attention): DebertaV2Attention(\n",
       "                  (self): DisentangledSelfAttention(\n",
       "                    (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (output): DebertaV2SelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): DebertaV2Intermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DebertaV2Output(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (rel_embeddings): Embedding(512, 768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rnn): LstmSeq2SeqEncoder(\n",
       "      (lstm): LSTM(768, 384, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (span_rep_layer): SpanRepLayer(\n",
       "      (span_rep_layer): SpanMarker(\n",
       "        (project_start): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.4, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        )\n",
       "        (project_end): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.4, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_project): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (prompt_rep_layer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.4, inplace=False)\n",
       "      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GLiNER.from_pretrained(\"urchade/gliner_multi\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb9179",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    {\n",
    "        \"text\": \"Apple was founded by Steve Jobs in California\",\n",
    "        \"entities\": [\n",
    "            {\"start\": 0, \"end\": 5, \"label\": \"COMPANY\"},\n",
    "            {\"start\": 20, \"end\": 30, \"label\": \"PERSON\"},\n",
    "            {\"start\": 34, \"end\": 44, \"label\": \"LOCATION\"}\n",
    "        ]\n",
    "    },\n",
    "    # Add more samples...\n",
    "]\n",
    "\n",
    "val_data = [\n",
    "    # Validation samples in same format\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4b77b",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create data loaders using model's built-in collate function\n",
    "train_loader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=4, \n",
    "    shuffle=True,\n",
    "    collate_fn=model.collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=4,\n",
    "    collate_fn=model.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c2838",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=2e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e5653",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f936a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                 for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                     for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "    \n",
    "    # Print epoch stats\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d69506",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ac898",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"fine_tuned_gliner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90198c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Load the model\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_multi\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
