{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f8edd7",
   "metadata": {},
   "source": [
    "# Fine-Tuning Preparation\n",
    "Based on the analysis, the confidence score is correlated with the number of labels predicted. This means that by increasing the number of predicted labels, the confidence score will increase as wel. However, this would only appply after the prediction.\n",
    "The good news is that from the analysis, there are a few label types that have shown to have poor high confidence score ratio against low confidence score. This is while some low frequency labels have good ratio. So, to increase the confidence score with less label frequency. The training data needs to be augmented. Here, there are two things that can be done for this augmentation. These are:\n",
    "- get contextual texts that corresponds to poor ratio labels.\n",
    "- synthesize training data for rare texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e800ff",
   "metadata": {},
   "source": [
    "------------\n",
    "-----------\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879704cf",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15694c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gliner import GLiNER\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7925697",
   "metadata": {},
   "source": [
    "### Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ce69f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 30448.67it/s]\n",
      "C:\\Users\\Arif Irfan Ibrahim\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpanModel(\n",
       "  (token_rep_layer): Encoder(\n",
       "    (bert_layer): Transformer(\n",
       "      (model): DebertaV2Model(\n",
       "        (embeddings): DebertaV2Embeddings(\n",
       "          (word_embeddings): Embedding(250105, 768, padding_idx=0)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): DebertaV2Encoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x DebertaV2Layer(\n",
       "              (attention): DebertaV2Attention(\n",
       "                (self): DisentangledSelfAttention(\n",
       "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): DebertaV2SelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): DebertaV2Intermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DebertaV2Output(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (rel_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (rnn): LstmSeq2SeqEncoder(\n",
       "    (lstm): LSTM(768, 384, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (span_rep_layer): SpanRepLayer(\n",
       "    (span_rep_layer): SpanMarker(\n",
       "      (project_start): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.4, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "      (project_end): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.4, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "      (out_project): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (prompt_rep_layer): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # use GPU if available\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_multi\")\n",
    "model.model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb9179",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913aa722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "data_path = \"your_data.json\"\n",
    "batch_size = 2\n",
    "num_epoch = 10\n",
    "learning_rate = 2e-5\n",
    "output_dir = \"../gliner_fine_tuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a125ec7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mdata_path\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     raw_data = json.load(f)\n",
      "\u001b[31mNameError\u001b[39m: name 'data_path' is not defined"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data validation\n",
    "valid_data = []\n",
    "for sample in raw_data:\n",
    "    if 'text' not in sample or 'entities' not in sample:\n",
    "        continue\n",
    "        \n",
    "    valid_entities = []\n",
    "    for entity in sample['entities']:\n",
    "        if ('start' in entity and 'end' in entity and 'label' in entity and\n",
    "            0 <= entity['start'] < entity['end'] <= len(sample['text'])):\n",
    "            valid_entities.append(entity)\n",
    "    \n",
    "    if valid_entities:\n",
    "        valid_data.append({\n",
    "            'text': sample['text'],\n",
    "            'entities': valid_entities\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data spliting (train/val/test)\n",
    "train_val_data, test_data = train_test_split(\n",
    "    valid_data, \n",
    "    test_size=0.2,              # 20% for test\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    train_val_data,\n",
    "    test_size=0.15/(1-0.15),    # 15% for validation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# display\n",
    "print(f\"Total samples: {len(valid_data)}\")\n",
    "print(f\"Train: {len(train_data)} | Val: {len(val_data)} | Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5206dd80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# data loader\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_loader = DataLoader(train_data, batch_size=\u001b[43mbatch_size\u001b[49m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m val_loader = DataLoader(val_data, batch_size=batch_size)\n",
      "\u001b[31mNameError\u001b[39m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "# data loader\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.AdamW(model.model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e5653",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f936a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Starting training for {num_epoch} epochs...\")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epoch):\n",
    "    # Training\n",
    "    model.model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        texts = [item['text'] for item in batch]\n",
    "        spans_list = [item['entities'] for item in batch]\n",
    "        \n",
    "        inputs = model.tokenize(texts, spans_list)\n",
    "        inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                 for k, v in inputs.items()}\n",
    "        \n",
    "        outputs = model.model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            texts = [item['text'] for item in batch]\n",
    "            spans_list = [item['entities'] for item in batch]\n",
    "            \n",
    "            inputs = model.tokenize(texts, spans_list)\n",
    "            inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                     for k, v in inputs.items()}\n",
    "            \n",
    "            outputs = model.model(**inputs)\n",
    "            val_loss += outputs.loss.item()\n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    epoch_dir = os.path.join(output_dir, f\"epoch_{epoch+1}\")\n",
    "    model.save_pretrained(epoch_dir)\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        model.save_pretrained(os.path.join(output_dir, \"best_model\"))\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epoch} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d69506",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ac898",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(os.path.join(output_dir, \"final_model\"))\n",
    "print(\"Training complete! Saved to:\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
