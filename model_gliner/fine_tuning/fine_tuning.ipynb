{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f8edd7",
   "metadata": {},
   "source": [
    "# Fine-Tuning Preparation\n",
    "Based on the analysis, the confidence score is correlated with the number of labels predicted. This means that by increasing the number of predicted labels, the confidence score will increase as wel. However, this would only appply after the prediction.\n",
    "The good news is that from the analysis, there are a few label types that have shown to have poor high confidence score ratio against low confidence score. This is while some low frequency labels have good ratio. So, to increase the confidence score with less label frequency. The training data needs to be augmented. Here, there are two things that can be done for this augmentation. These are:\n",
    "- get contextual texts that corresponds to poor ratio labels.\n",
    "- synthesize training data for rare texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e800ff",
   "metadata": {},
   "source": [
    "------------\n",
    "-----------\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879704cf",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15694c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arif Irfan Ibrahim\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gliner import GLiNER\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7925697",
   "metadata": {},
   "source": [
    "### Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16adbef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ce69f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 57260.12it/s]\n",
      "C:\\Users\\Arif Irfan Ibrahim\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpanModel(\n",
       "  (token_rep_layer): Encoder(\n",
       "    (bert_layer): Transformer(\n",
       "      (model): DebertaV2Model(\n",
       "        (embeddings): DebertaV2Embeddings(\n",
       "          (word_embeddings): Embedding(250105, 768, padding_idx=0)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): DebertaV2Encoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x DebertaV2Layer(\n",
       "              (attention): DebertaV2Attention(\n",
       "                (self): DisentangledSelfAttention(\n",
       "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): DebertaV2SelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): DebertaV2Intermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DebertaV2Output(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (rel_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (rnn): LstmSeq2SeqEncoder(\n",
       "    (lstm): LSTM(768, 384, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (span_rep_layer): SpanRepLayer(\n",
       "    (span_rep_layer): SpanMarker(\n",
       "      (project_start): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.4, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "      (project_end): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.4, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "      (out_project): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (prompt_rep_layer): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_multi\")\n",
    "model.model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb9179",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913aa722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "data_path = \"training_data.json\"  # Path to your training data\n",
    "output_dir = r\"..\\fine_tuned_model\"   # Directory to save the fine-tuned model\n",
    "batch_size = 4                    # Adjust based on your GPU memory\n",
    "learning_rate = 2e-5              # Standard learning rate for fine-tuning\n",
    "num_epochs = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a125ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b1dc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 2000\n",
      "Train: 1300 | Val: 300 | Test: 400\n"
     ]
    }
   ],
   "source": [
    "# data spliting (train/val/test)\n",
    "train_val_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_ratio = 0.15\n",
    "val_split = val_ratio / (1 - 0.2)  # 0.15 / 0.8 = 0.1875\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=val_split, random_state=42)\n",
    "\n",
    "print(f\"Total samples: {len(data)}\")\n",
    "print(f\"Train: {len(train_data)} | Val: {len(val_data)} | Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e5653",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908f4885",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GLiNER' object has no attribute 'fine_tune'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfine_tune\u001b[49m(\n\u001b[32m      2\u001b[39m     train_data=train_data,\n\u001b[32m      3\u001b[39m     val_data=val_data,\n\u001b[32m      4\u001b[39m     output_dir=output_dir,\n\u001b[32m      5\u001b[39m     batch_size=batch_size,\n\u001b[32m      6\u001b[39m     learning_rate=learning_rate,\n\u001b[32m      7\u001b[39m     num_epochs=num_epochs,\n\u001b[32m      8\u001b[39m     device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1962\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1960\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1961\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1962\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1963\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1964\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'GLiNER' object has no attribute 'fine_tune'"
     ]
    }
   ],
   "source": [
    "model.fine_tune(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    output_dir=output_dir,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    num_epochs=num_epochs,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d69506",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ac898",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(os.path.join(output_dir, \"final_model\"))\n",
    "print(\"Training complete! Saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cccef85",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ner'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test_data:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEvaluating on test set...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\gliner\\model.py:520\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(self, test_data, flat_ner, multi_label, threshold, batch_size, entity_types)\u001b[39m\n\u001b[32m    518\u001b[39m         start_text_idx = start_token_idx_to_text_idx[start_token_idx]\n\u001b[32m    519\u001b[39m         end_text_idx = end_token_idx_to_text_idx[end_token_idx]\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m         entities.append(\n\u001b[32m    521\u001b[39m             {\n\u001b[32m    522\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m\"\u001b[39m: start_token_idx_to_text_idx[start_token_idx],\n\u001b[32m    523\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mend\u001b[39m\u001b[33m\"\u001b[39m: end_token_idx_to_text_idx[end_token_idx],\n\u001b[32m    524\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: texts[i][start_text_idx:end_text_idx],\n\u001b[32m    525\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m: ent_type,\n\u001b[32m    526\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m: ent_score,\n\u001b[32m    527\u001b[39m             }\n\u001b[32m    528\u001b[39m         )\n\u001b[32m    529\u001b[39m     all_entities.append(entities)\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_entities\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\gliner\\data_processing\\collator.py:29\u001b[39m, in \u001b[36mDataCollator.__call__\u001b[39m\u001b[34m(self, input_x)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_x):\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     raw_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_processor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollate_raw_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_types\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mentity_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     model_input = \u001b[38;5;28mself\u001b[39m.data_processor.collate_fn(raw_batch, prepare_labels=\u001b[38;5;28mself\u001b[39m.prepare_labels)\n\u001b[32m     32\u001b[39m     model_input.update({\u001b[33m\"\u001b[39m\u001b[33mspan_idx\u001b[39m\u001b[33m\"\u001b[39m: raw_batch[\u001b[33m'\u001b[39m\u001b[33mspan_idx\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mspan_idx\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m raw_batch \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[32m     33\u001b[39m                         \u001b[33m\"\u001b[39m\u001b[33mspan_mask\u001b[39m\u001b[33m\"\u001b[39m: raw_batch[\u001b[33m\"\u001b[39m\u001b[33mspan_mask\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mspan_mask\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m raw_batch \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     34\u001b[39m                         \u001b[33m\"\u001b[39m\u001b[33mtext_lengths\u001b[39m\u001b[33m\"\u001b[39m: raw_batch[\u001b[33m'\u001b[39m\u001b[33mseq_length\u001b[39m\u001b[33m'\u001b[39m]})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\gliner\\data_processing\\processor.py:192\u001b[39m, in \u001b[36mcollate_raw_batch\u001b[39m\u001b[34m(self, batch_list, entity_types, negatives, class_to_ids, id_to_classes)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prepare_labels \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.decoder_mode == \u001b[33m'\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(entities, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         entities_ = \u001b[38;5;28mlist\u001b[39m(entities)\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    194\u001b[39m         entities_ = [ent \u001b[38;5;28;01mfor\u001b[39;00m sample_entities \u001b[38;5;129;01min\u001b[39;00m entities \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m sample_entities]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\gliner\\data_processing\\processor.py:162\u001b[39m, in \u001b[36mbatch_generate_class_mappings\u001b[39m\u001b[34m(self, batch_list, negatives)\u001b[39m\n\u001b[32m    159\u001b[39m input_texts, prompt_lengths = \u001b[38;5;28mself\u001b[39m.prepare_inputs(texts, entities, blank=blank)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.preprocess_text:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     input_texts = \u001b[38;5;28mself\u001b[39m.prepare_texts(input_texts)\n\u001b[32m    164\u001b[39m tokenized_inputs = \u001b[38;5;28mself\u001b[39m.transformer_tokenizer(\n\u001b[32m    165\u001b[39m     input_texts,\n\u001b[32m    166\u001b[39m     is_split_into_words=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m     padding=\u001b[33m\"\u001b[39m\u001b[33mlongest\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    170\u001b[39m )\n\u001b[32m    171\u001b[39m words_masks = \u001b[38;5;28mself\u001b[39m.prepare_word_mask(texts, tokenized_inputs, prompt_lengths)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\gliner\\data_processing\\processor.py:77\u001b[39m, in \u001b[36mget_negatives\u001b[39m\u001b[34m(batch_list, sampled_neg)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_negatives\u001b[39m(batch_list: List[Dict], sampled_neg: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     76\u001b[39m     ent_types = []\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch_list:\n\u001b[32m     78\u001b[39m         types = \u001b[38;5;28mset\u001b[39m([el[-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m b[\u001b[33m'\u001b[39m\u001b[33mner\u001b[39m\u001b[33m'\u001b[39m]])\n\u001b[32m     79\u001b[39m         ent_types.extend(\u001b[38;5;28mlist\u001b[39m(types))\n",
      "\u001b[31mKeyError\u001b[39m: 'ner'"
     ]
    }
   ],
   "source": [
    "if test_data:\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    results = model.evaluate(test_data, batch_size=batch_size)\n",
    "    print(f\"Test F1: {results['f1']:.4f}, Precision: {results['precision']:.4f}, Recall: {results['recall']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
